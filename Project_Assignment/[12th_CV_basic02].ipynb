{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb8519ca",
   "metadata": {},
   "source": [
    "내가 해야 할 것들  \n",
    "1. 시각화 정착\n",
    "2. 3번 테스트 이전까지 완벽하게 구성 완료하기\n",
    "3. train에 사진 300장 추가, test3에 사진 추가해서 정확도 70%까지 높혀보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a60d869",
   "metadata": {},
   "source": [
    "# 주제: 가위바위보 분류하기\n",
    "\n",
    "## 데이터\n",
    "train data: 직접 찍은 가위, 바위, 보 사진 각각 365장 총 1095장  \n",
    "test data: 다른 사람들의 가위, 바위, 보 사진 각각 100장 총 300장, 3번 시도  \n",
    "\n",
    "## 목표\n",
    "1. 여러가지 평가지표 시각화하기 (train acc / train loss / val acc / val loss )\n",
    "2. 오버피팅을 극복하기 위해 다양한 데이터셋 사용, 정규화, 모델구성 변화 등 시도하기\n",
    "3. 정확도 60% 넘기기!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4adfc0",
   "metadata": {},
   "source": [
    "### (1) 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6255b248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "1.21.4\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a13fcb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a53465",
   "metadata": {},
   "source": [
    "### (2) 데이터 전처리\n",
    "모든 이미지를 28x28 사이즈로 바꾸고 픽셀값을 0~1 사이의 값으로 정규화한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86ff8333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365  images to be resized.\n",
      "365  images resized.\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3efcf89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365  images to be resized.\n",
      "365  images resized.\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "# [[YOUR CODE]]\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "# [[YOUR CODE]]\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34ada001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365  images to be resized.\n",
      "365  images resized.\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "# [[YOUR CODE]]\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "# [[YOUR CODE]]\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf734a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 1095 입니다.\n",
      "x_train shape: (1095, 28, 28, 3)\n",
      "y_train shape: (1095,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data=1095):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b8c1ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAW60lEQVR4nO2dW4xkV3WG/1W3vndPz4XxjD14zDAQDEkMallEoIQIBRm/jFEkghUhR0IMD1gCiYcg8oAfrSiAeIgsDcHCJASEBAg/OAHHseKgJOC2Y3wlzODbzLjn3j093dW3qlp56HLUmN7/aup0V5Wy/09qdXWt2ufsc6r+rqrz77WWuTuEEP//KfV6AkKI7iCxC5EJErsQmSCxC5EJErsQmVDp5s6GhoZ8bHws/QAzOp5FzYL/W9G2eZjvPRhr0QOiPReZW68pMLXQJ9pBJ6mXJlURh+zq3ByWFhc3PeuFxG5mtwH4KoAygL9z93vZ48fGx/Cnf/5nyXipxAVbLpeTsWp1gI6tVPihsm0DgJXTc7NAjeVSlW87GB+dFzY+GhtTbHyz0ux4bPSib7VafHwzHXfn5zzadxhvdb79ZoHj/of77kvGOn4mzawM4G8BfBjAzQDuNLObO92eEGJnKfJv+1YAp9z9RXdfBfAdAMe2Z1pCiO2miNivB3B6w99n2vf9GmZ23MymzWx6aWmpwO6EEEXY8avx7n7C3afcfWpoaGindyeESFBE7GcBHNrw9w3t+4QQfUgRsT8O4KiZ3WRmNQAfA/Dg9kxLCLHddGy9uXvDzO4G8COsW2/3u/tzdJAZ1i/ip8KRxcTtsX6laGZhNJ5Zb0XGbgdFjr2w/UXi0bSK7rvV6nx8y7mlyLbN9lrIZ3f3hwA8VGQbQojuoOWyQmSCxC5EJkjsQmSCxC5EJkjsQmSCxC5EJnQ1nx0IUkWjdMwS8YRZDECQ0YhWkD1tJFMzsqqtvLM+O0t5jHz0eO0C93wjvMS87mJpokGGK33Sw/TYgj57s1nAZw/m1mQ+PNmu3tmFyASJXYhMkNiFyASJXYhMkNiFyASJXYhM6LL1ZjAQqyfwx9jYsJpnYEEFGYkwK2JvBdVjg3ho3LHxoS8Y5XoWrC4bzz696yDV0wOLillYO5k+CwDNVqPj8ZH11ulx6Z1diEyQ2IXIBIldiEyQ2IXIBIldiEyQ2IXIBIldiEzoeoorSyUN/WZaGrhYx89C3U4jTzby+AuWc2Y+fjnsJx3tu2CKK3k/Ke51832zp7zlvLts4fLfjc63H60fcOrhy2cXInskdiEyQWIXIhMkdiEyQWIXIhMkdiEyQWIXIhO66rM7vFCOMUuFj+zgKKc89OEL5IxH2w698CjXnoyPPP7YZ99B4r7JPBzlfRdoi2wFWi4DWylVnfbhY5+9s1LShcRuZi8DuAagCaDh7lNFtieE2Dm24539j9390jZsRwixg+g7uxCZUFTsDuDHZvaEmR3f7AFmdtzMps1serm+VHB3QohOKfox/v3uftbM3gTgYTP7hbs/tvEB7n4CwAkA2Hfd/mLZBUKIjin0zu7uZ9u/LwD4AYBbt2NSQojtp2Oxm9mImY29fhvAhwA8u10TE0JsL0U+xu8H8IO2f10B8I/u/s90hPNWtqWg7TIznC34t8XqvgNAOchnZ98/SFfi9X0XqJ0OABb4rqzrcimqxb/DPjs78qL57LFPzxLaO/fotwLz0dsPIKEoUT/YdoKOxe7uLwL4/U7HCyG6i6w3ITJBYhciEyR2ITJBYhciEyR2ITKh66Wki7SqLREjJ3CYAGf5sbHdQdNQA5uFzRvYiv0V2GfktJWisTtsvZVIy+fCbZEjS5M9L1EKa2iXFiyxTa23zqy1CL2zC5EJErsQmSCxC5EJErsQmSCxC5EJErsQmSCxC5EJXffZKySNNWqb3Gym/cdKmfvog4ODNO6NNRpvrK6mt12r0bGtYNuR010p86epSo7dG6y9L7BKjguIffpacOwTE+PJ2NzcHB3Lnm9gCz47S5kOUp7X1vh5GRgYoPFmsEZgbW0lGQvbh3eYfqt3diEyQWIXIhMkdiEyQWIXIhMkdiEyQWIXIhMkdiEyocs+u6PRTPuX1Wg6rDRwk/vBHvjJrUYQX0175R7Ukh4dHKLx4cCrrpT4GoJdExPJ2Lve8Tt07MGDB2n8Fy+8QOOPPvoojZ+euZCM7du3j46d3JU+LgCYry/SeH053W6sXOWvtXJQm3xhYYHGq9UqjZ87dy4ZW15epmPHRkaTscZa+nWqd3YhMkFiFyITJHYhMkFiFyITJHYhMkFiFyITJHYhMqHr+ezMvxyocD8ZSMejlstli/oq8/gQ8WXHhriP/t5bp2j87UeO0vjuXemccACYvXwlGfMmz6UfHeAvgbffdCON1/BHNH760tV07PRpOvbcmVdovBR45TWyvmF5hXvZjaAGQTloL16t8tfywEB6bkNDI3TsDQevT8ZqJM8+fGc3s/vN7IKZPbvhvt1m9rCZnWz/noy2I4ToLVv5GP8NALe94b7PA3jE3Y8CeKT9txCijwnF7u6PAXjj58RjAB5o334AwB3bOy0hxHbT6QW6/e4+0759DsD+1APN7LiZTZvZ9PJSeq2yEGJnKXw13tc71CWvbrn7CXefcvepweBClhBi5+hU7OfN7AAAtH+nU5uEEH1Bp2J/EMBd7dt3Afjh9kxHCLFThD67mX0bwAcA7DWzMwC+COBeAN81s08AeAXAR7e0N3e0VtPf2xtBLW+66aC+eSnwTRH0hq+QNQCDFb7v64O87ZXFeRo/fy3tVQPACsnbbqzwPP3Fy5dpfGyEe77vPHqExv/gfTckYz97/Gd07GP/8Z80vhh45aVK+r2s0eLP2XCV14VfC5ZtPPnkkzReKqfz3Q8dOkTHDhIfntWcD8Xu7ncmQh+Mxgoh+gctlxUiEyR2ITJBYhciEyR2ITJBYhciE7qa4moG1IiFxWIAgBbxO1gMAHFhAAClMrdixkjL58mxdGlfADh35lUav3ThIo03iLUGABPj6f2PklRKAIDztshzQZnrXWM8/fbK3LVk7B1HuG1XDZ60/37uGRo/+dLLyVg9KC1eCyzHC5f4OrJKhUtrz960HXvgQDqFFQCGSClpI2XH9c4uRCZI7EJkgsQuRCZI7EJkgsQuRCZI7EJkgsQuRCZ01WdvNhqYu5JOqawFni487aWX08VyAAADwbZ5g12gNJT2ZeeDssGXLvJ0yVLgdUcptMsLaS+7Ts43EFbQxujQMI036rx1cf1M2o+u3MyPa2SAPytvPczLXM+TtsqzL75Ix5ZqfN/RazVqhT0wmD6v9SB1d/n8+WRMLZuFEBK7ELkgsQuRCRK7EJkgsQuRCRK7EJkgsQuRCV312Wu1ARy+Me2NDgS+apmUi66Uudc9FPimJeLhA8BAOX2q9kzwnO468cEB7pMDQH2el5pGI+3Tjw7zfPbdu3bxTa/xXPqrszy+7+BbkrGL52aSMQBYWK7T+MHDh2kcpD7C4gqftwXdi/bX+NqJ+Trf/tJyet1GMyhzzVZlsFex3tmFyASJXYhMkNiFyASJXYhMkNiFyASJXYhMkNiFyISu+uyAw0gCNWs3CwAVUhN7oMYPZTBowdtqNmjcW2l3c3WV5x83gnhrje+bHTcAlMihLy0u0rFn5nk76DFSoxwAJicnafy1M6eTsZGg3v61JX7eRnfxfbNeAiNBXXgf4K+X2UW+BqAVtABfbabj1QpfEzI8nJ57uUjdeDO738wumNmzG+67x8zOmtlT7Z/bo+0IIXrLVj7GfwPAbZvc/xV3v6X989D2TksIsd2EYnf3xwBc6cJchBA7SJELdHeb2dPtj/nJL09mdtzMps1suh6sFxZC7Bydiv0+AEcA3AJgBsCXUg909xPuPuXuU8NBUoYQYufoSOzuft7dm+7eAvA1ALdu77SEENtNR2I3swMb/vwIgGdTjxVC9Aehz25m3wbwAQB7zewMgC8C+ICZ3YL19NmXAXxqS3srldEaSnuEy6WgbnwpXWu7WuK+6Ypzr7pmvHZ7ubqSjDVb6RgADI/y/OT6Iu/PXh1I1wIHgPnLaa+8scL/nw/XdvNtXwmOrco9Yd+dvk5zbob3OL/uhjfT+MV5ft5albRXHqSMAx7UtB8eo/Hlq7ye/mA1/bw0G9yjX1pIr51okfUgodjd/c5N7v56NE4I0V9ouawQmSCxC5EJErsQmSCxC5EJErsQmdDVFFczQ5VYNaUSt3GqLJeTO2u8xi4AL3GrxSwdj1Jz5xd4OuRakOLaosWDgSaxiQaJ1QkAE+PcelvmDhIWl/kS6Gvn55KxkXFuX83OztL4OCktDgCrSNuGUUvlC7O8fPfyCrdDB4IU2dZKupR0qxm8WDtE7+xCZILELkQmSOxCZILELkQmSOxCZILELkQmSOxCZELXS0mzErtl46l9jKh0b5jSGFAi7X+dtHMGABhfBNAI/OK5Od7SefZiukTgSJAeWypP0PhKnZ/XZZJeCwB7b0p76WztAgAsBmWwF4hXDQDVoXSp6mur/LzUV/nahrHde2m8tcTntkZKSa8E6y4YatkshJDYhcgFiV2ITJDYhcgEiV2ITJDYhcgEiV2ITOiqz+7O/XCrcN+VdS6O/muVg3x1lme/Hk/7rtG2B0cDL3uV+8n1Rd66eGAsPbdqmeezrwbrE5ZIaWIAqK/wuQ0upM/N2XMzdOze63jOeSPwo/cevCEZ+7d/+hEdO7yL5/n/3r79NF6r8bLoZbJGIFp/4N5Zvrve2YXIBIldiEyQ2IXIBIldiEyQ2IXIBIldiEyQ2IXIhK767KWSYYD4j1Gt7VolPbZs/FBozXkA5aj1sKXzn1cbvK0xynzbQ+OTNL4nmPve69KxKrjfG059MGplzX32+fl0W+aVNZ7zPTycbtENAIePvo3Gj77zd5Oxl868RsfO1flxRT76SpMfW6WSfk7LZV7/gPnstL8B3er64ENm9qiZPW9mz5nZZ9r37zazh83sZPs3f8UKIXrKVj7GNwB8zt1vBvBeAJ82s5sBfB7AI+5+FMAj7b+FEH1KKHZ3n3H3J9u3rwF4AcD1AI4BeKD9sAcA3LFDcxRCbAO/1QU6MzsM4N0Afgpgv7u/vrj5HIBNFwub2XEzmzaz6cUFvgZcCLFzbFnsZjYK4HsAPuvuv9b1ztevGGx61cDdT7j7lLtPjYzypAwhxM6xJbGbWRXrQv+Wu3+/ffd5MzvQjh8AkL7sKoToOaH1ZuvX8r8O4AV3//KG0IMA7gJwb/v3D+PdGbUcotbHZmnLIWxrHPxfWwuskgXSu7h+bY6OHR/jNk2twi2mpRb/+rNGbKLWWuCtNbnNMzTAP421anz8YC19bHvG3kTHrqzy52TvXl7OmVlYx44do2P//aeP0/hC0Kq6FdQuZ4nFkfXGYNbbVnz29wH4OIBnzOyp9n1fwLrIv2tmnwDwCoCPdjxDIcSOE4rd3X8CJLsYfHB7pyOE2Cm0XFaITJDYhcgEiV2ITJDYhcgEiV2ITOhyy+Zi8BK6QXndoDxvMxh/bSntZV+enaVj11rp1sEAcPA67hd7mfvwV+vpNQCNoDXx5PguGh8c53OfXeTtpCuNdLnnZpOvjTj/Gk9DPXXqFI2/dindyvod734PHRut+Th58iSNv+lAuow1AKyS56XpnbcuZxrRO7sQmSCxC5EJErsQmSCxC5EJErsQmSCxC5EJErsQmdBVn93MUCmTctBByeUSzYXnhzIwyMtUR5QX0vNugOcfn78yT+NH3vp2Gj80wtsHj0+kffoqX16A/ft4Tnmtyo/tap0f29zpdFvmVrC2ISrXvFDnef5Dk+nztrTE89GrQVnzxUW+7yi+2kh76Y2gjTbLWZfPLoSQ2IXIBYldiEyQ2IXIBIldiEyQ2IXIBIldiEzobj67A81m2iOsVvn/nmo17X2WiQcPAC2aCw+srqbzrgGgkSywCwyNTNCxkV98ea5O4+OjPJ/9rW97ZzLmQT38q5d5b4/hYX5sYxNjND57Jh1bWQty7Sd4Y+DVoK78ykq6Zv78PF8fsHs3X9tw3cEDNG4lvj5hoErWmzR4nv/yMm8nnULv7EJkgsQuRCZI7EJkgsQuRCZI7EJkgsQuRCZI7EJkwlb6sx8C8E0A+7FenP2Eu3/VzO4B8EkAF9sP/YK7P8S2VSpXMD6W9k5rNZ7PXq6mp8trym8hd3qQ+6KT5T3J2Mgo96IP7D9I42MjvDZ7qcV918tX0l75z5/4Lzp2zx7uk++a5P3ZD72Z+80zv3w2GVsMcsovXbpE48uBH71m6ee0MszP+TLfdFhXvlXihQRYTnpEp2O3sqimAeBz7v6kmY0BeMLMHm7HvuLuf9PRnoUQXWUr/dlnAMy0b18zsxcAXL/TExNCbC+/1Xd2MzsM4N0Aftq+624ze9rM7jezTT+fm9lxM5s2s+mFa7xVkBBi59iy2M1sFMD3AHzW3ecB3AfgCIBbsP7O/6XNxrn7CXefcvep0TH+/VAIsXNsSexmVsW60L/l7t8HAHc/7+5Nd28B+BqAW3dumkKIooRit/VLf18H8IK7f3nD/Rsvw34EQPqyqxCi52zlavz7AHwcwDNm9lT7vi8AuNPMbsG6HfcygE9FG/KWY3mJpJISqwQABslsnaSgAoAHbkWVpBwCwOAISa81PvaRf32MxueuBC2fl3hZ4oWrF5Oxl371PB37mbs/SeOjI0M0vrLMr8NMTKRtybkgzXR2nqffztZ5avA8SVtuBs93ZYhbc62o3HM5eMEx+yyw9WicbHcrV+N/AmyqJOqpCyH6C62gEyITJHYhMkFiFyITJHYhMkFiFyITJHYhMqGrpaRL5QrGxtOpotWgPfBKI50SeWaG1CwG8KuXTtH46VfP0vgV0nZ5qc5LGo+P8pLIJ5//BY23VtMlkQGgVk77ySuLPE30yOEbabxa4X7xq6+epPHJyfSxnz7Lz3k98NFLQVpzs5ROma6Nnqdjh8Y7L1MNAEM1vj6B+eFRCmunKa56ZxciEyR2ITJBYhciEyR2ITJBYhciEyR2ITJBYhciEywqwbytOzO7COCVDXftBcCN4N7Rr3Pr13kBmlunbOfcbnT3fZsFuir239i52bS7T/VsAoR+nVu/zgvQ3DqlW3PTx3ghMkFiFyITei32Ez3eP6Nf59av8wI0t07pytx6+p1dCNE9ev3OLoToEhK7EJnQE7Gb2W1m9j9mdsrMPt+LOaQws5fN7Bkze8rMpns8l/vN7IKZPbvhvt1m9rCZnWz/5sny3Z3bPWZ2tn3unjKz23s0t0Nm9qiZPW9mz5nZZ9r39/TckXl15bx1/Tu7mZUB/BLAnwA4A+BxAHe6O+9m0CXM7GUAU+7e8wUYZvaHABYAfNPd39W+768BXHH3e9v/KCfd/S/7ZG73AFjodRvvdreiAxvbjAO4A8BfoIfnjszro+jCeevFO/utAE65+4vuvgrgOwCO9WAefY+7PwbgyhvuPgbggfbtB7D+Yuk6ibn1Be4+4+5Ptm9fA/B6m/Genjsyr67QC7FfD+D0hr/PoL/6vTuAH5vZE2Z2vNeT2YT97j7Tvn0OwP5eTmYTwjbe3eQNbcb75tx10v68KLpA95u8393fA+DDAD7d/rjal/j6d7B+8k631Ma7W2zSZvz/6OW567T9eVF6IfazAA5t+PuG9n19gbufbf++AOAH6L9W1Odf76Db/s27H3aRfmrjvVmbcfTBuetl+/NeiP1xAEfN7CYzqwH4GIAHezCP38DMRtoXTmBmIwA+hP5rRf0ggLvat+8C8MMezuXX6Jc23qk24+jxuet5+3N37/oPgNuxfkX+VwD+qhdzSMzrLQB+3v55rtdzA/BtrH+sW8P6tY1PANgD4BEAJwH8C4DdfTS3vwfwDICnsS6sAz2a2/ux/hH9aQBPtX9u7/W5I/PqynnTclkhMkEX6ITIBIldiEyQ2IXIBIldiEyQ2IXIBIldiEyQ2IXIhP8FTtujR8JvyHcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "index = 566\n",
    "plt.imshow(x_train[index])\n",
    "print('라벨: ', y_train[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198754db",
   "metadata": {},
   "source": [
    "### (3) 모델 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c0a3d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 35,875\n",
      "Trainable params: 35,875\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# model을 직접 만들어 보세요.\n",
    "# Hint! model의 입력/출력부에 특히 유의해 주세요. 가위바위보 데이터셋은 MNIST 데이터셋과 어떤 점이 달라졌나요?\n",
    "# [[YOUR CODE]]\n",
    "n_channel_1=32\n",
    "n_channel_2=32\n",
    "n_dense=32\n",
    "n_train_epoch=11\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba1079a",
   "metadata": {},
   "source": [
    "### (4) 모델 컴파일 및 학습하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d3ddef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "35/35 [==============================] - 3s 5ms/step - loss: 1.0609 - accuracy: 0.4840\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.8724 - accuracy: 0.6648\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.6337 - accuracy: 0.7580\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4909 - accuracy: 0.8174\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3436 - accuracy: 0.8822\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2720 - accuracy: 0.9151\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1922 - accuracy: 0.9452\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1532 - accuracy: 0.9598\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1290 - accuracy: 0.9671\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1142 - accuracy: 0.9635\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feeb81331f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.compile()과 model.fit()을 사용해 봅시다.\n",
    "# [[YOUR CODE]]\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train_norm, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9819cd3a",
   "metadata": {},
   "source": [
    "### (5) 테스트용 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7f90a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "# x_test, y_test를 만드는 방법은 x_train, y_train을 만드는 방법과 아주 유사합니다.\n",
    "# [[YOUR CODE]]\n",
    "#테스트용 사진 resize\n",
    "\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "#바위\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "#보\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
    "(x_test, y_test)=load_data(image_dir_path, 300)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75de0bf",
   "metadata": {},
   "source": [
    "### (6) 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8984f7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 445.1967 - accuracy: 0.3200\n",
      "test_loss: 445.19671630859375 \n",
      "test_accuracy: 0.3199999928474426\n"
     ]
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.evaluate()을 사용해 봅시다.\n",
    "# [[YOUR CODE]]\n",
    "# 모델 평가\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "374bc5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 결과 시각화\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d325816f",
   "metadata": {},
   "source": [
    "### (7) 더 좋은 결과를 위한 시도들\n",
    "#### 1. 모델 구성을 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "584bbad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 328,739\n",
      "Trainable params: 328,739\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_channel_1=32\n",
    "n_channel_2=64\n",
    "n_dense=256\n",
    "n_train_epoch=11\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Dropout(0.25))\n",
    "\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Dropout(0.25))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e91d1da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "35/35 [==============================] - 1s 9ms/step - loss: 1.0981 - accuracy: 0.3717\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.8581 - accuracy: 0.5991\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4696 - accuracy: 0.8201\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3696 - accuracy: 0.8849\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1646 - accuracy: 0.9388\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0919 - accuracy: 0.9753\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1147 - accuracy: 0.9534\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0534 - accuracy: 0.9845\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0255 - accuracy: 0.9936\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0774 - accuracy: 0.9781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fedfcea86a0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train_norm, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4238f01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 32.3456 - accuracy: 0.6233\n",
      "test_loss: 32.345577239990234 \n",
      "test_accuracy: 0.6233333349227905\n"
     ]
    }
   ],
   "source": [
    "# 모델 시험\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10babced",
   "metadata": {},
   "source": [
    "-> 당황스럽게도 첫번째 시도에서 정확도 62%가 나왔다!! 일단 목표는 성공했는데 다른 사진들로도 테스트도 해보고 정확도를 더 높혀봐야겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abde870c",
   "metadata": {},
   "source": [
    "#### 2. 다른 데이터로도 평가해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d04f73ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test2/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "#바위\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test2/rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "#보\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test2/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test2\"\n",
    "(x_test, y_test)=load_data(image_dir_path, 300)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "598cf742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 261.9996 - accuracy: 0.5167\n",
      "test_loss: 261.99957275390625 \n",
      "test_accuracy: 0.5166666507720947\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2152d86e",
   "metadata": {},
   "source": [
    "-> 다른 사람의 파일로 하니 51%로 정확도가 떨어졌다. 모델 구성을 다시 바꿔보아야겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9f79d88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_86 (Conv2D)           (None, 26, 26, 64)        1792      \n",
      "_________________________________________________________________\n",
      "conv2d_87 (Conv2D)           (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_88 (Conv2D)           (None, 12, 12, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_89 (Conv2D)           (None, 12, 12, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_90 (Conv2D)           (None, 4, 4, 32)          9248      \n",
      "_________________________________________________________________\n",
      "conv2d_91 (Conv2D)           (None, 2, 2, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 89,539\n",
      "Trainable params: 89,539\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_channel_1=64\n",
    "n_channel_2=32\n",
    "n_channel_3=32\n",
    "n_dense=128\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Dropout(0.25))\n",
    "\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu',padding='same'))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu', padding='same'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Dropout(0.25))\n",
    "\n",
    "model.add(keras.layers.Conv2D(n_channel_3, (3,3), activation='relu'))\n",
    "model.add(keras.layers.Conv2D(n_channel_3, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Dropout(0.25))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2fc2787d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "35/35 [==============================] - 1s 10ms/step - loss: 1.1041 - accuracy: 0.3242\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 1.0990 - accuracy: 0.3443\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 1.0971 - accuracy: 0.3543\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.9732 - accuracy: 0.4886\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.7646 - accuracy: 0.6073\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.6646 - accuracy: 0.6566\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.5768 - accuracy: 0.6913\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4909 - accuracy: 0.7772\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4175 - accuracy: 0.8155\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4034 - accuracy: 0.8356\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fede810cb80>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train_norm, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "82683f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 103.2350 - accuracy: 0.5833\n",
      "test_loss: 103.2349853515625 \n",
      "test_accuracy: 0.5833333134651184\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e72e31",
   "metadata": {},
   "source": [
    "-> epoch를 높혔을 때는 오히려 과적합되어 모델 평가할 때는 더 정확도가 떨어져서 10으로 고정하였다. layer을 추가할 때 오류가 나서 두번째 layer뭉터기에 padding = 'same'을 추가하니 더 정확도가 높게 나왔다. 모델 구성을 더 깊게 만들면서 차원이 맞지 않을 땐 padding='same'을 추가해야겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8828a246",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_204 (Conv2D)          (None, 26, 26, 64)        1792      \n",
      "_________________________________________________________________\n",
      "conv2d_205 (Conv2D)          (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_95 (MaxPooling (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_116 (Dropout)        (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_206 (Conv2D)          (None, 12, 12, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_207 (Conv2D)          (None, 12, 12, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_96 (MaxPooling (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_117 (Dropout)        (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_208 (Conv2D)          (None, 4, 4, 32)          9248      \n",
      "_________________________________________________________________\n",
      "conv2d_209 (Conv2D)          (None, 2, 2, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_97 (MaxPooling (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_118 (Dropout)        (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_26 (Flatten)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "dropout_119 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 89,539\n",
      "Trainable params: 89,539\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_channel_1=64\n",
    "n_channel_2=32\n",
    "n_channel_3=32\n",
    "n_dense=128\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Dropout(0.25))\n",
    "\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu',padding='same'))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu', padding='same'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Dropout(0.25))\n",
    "\n",
    "model.add(keras.layers.Conv2D(n_channel_3, (3,3), activation='relu'))\n",
    "model.add(keras.layers.Conv2D(n_channel_3, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Dropout(0.25))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "94524957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "35/35 [==============================] - 1s 6ms/step - loss: 1.1002 - accuracy: 0.3397\n",
      "Epoch 2/40\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 1.1010 - accuracy: 0.3178\n",
      "Epoch 3/40\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 1.0930 - accuracy: 0.3909\n",
      "Epoch 4/40\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 1.0136 - accuracy: 0.4594\n",
      "Epoch 5/40\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.7904 - accuracy: 0.5900\n",
      "Epoch 6/40\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.6329 - accuracy: 0.7068\n",
      "Epoch 7/40\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.5327 - accuracy: 0.7790\n",
      "Epoch 8/40\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4335 - accuracy: 0.8402\n",
      "Epoch 9/40\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.2268 - accuracy: 0.9169\n",
      "Epoch 10/40\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.1489 - accuracy: 0.9489\n",
      "Epoch 11/40\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.1156 - accuracy: 0.9589\n",
      "Epoch 12/40\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.1323 - accuracy: 0.9616\n",
      "Epoch 13/40\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0693 - accuracy: 0.9836\n",
      "Epoch 14/40\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0534 - accuracy: 0.9836\n",
      "Epoch 15/40\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0246 - accuracy: 0.9927\n",
      "Epoch 16/40\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0307 - accuracy: 0.9909\n",
      "Epoch 17/40\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0391 - accuracy: 0.9890\n",
      "Epoch 18/40\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0387 - accuracy: 0.9909\n",
      "Epoch 19/40\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0314 - accuracy: 0.9863\n",
      "Epoch 20/40\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0239 - accuracy: 0.9945\n",
      "Epoch 21/40\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0322 - accuracy: 0.9890\n",
      "Epoch 22/40\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0427 - accuracy: 0.9845\n",
      "Epoch 23/40\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0200 - accuracy: 0.9936\n",
      "Epoch 24/40\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0105 - accuracy: 0.9963\n",
      "Epoch 25/40\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0060 - accuracy: 0.9982\n",
      "Epoch 26/40\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0314 - accuracy: 0.9900\n",
      "Epoch 27/40\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0994 - accuracy: 0.9671\n",
      "Epoch 28/40\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0304 - accuracy: 0.9918\n",
      "Epoch 29/40\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0345 - accuracy: 0.9918\n",
      "Epoch 30/40\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0493 - accuracy: 0.9817\n",
      "Epoch 31/40\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0108 - accuracy: 0.9973\n",
      "Epoch 32/40\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0042 - accuracy: 0.9991\n",
      "Epoch 33/40\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0054 - accuracy: 0.9991\n",
      "Epoch 34/40\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0058 - accuracy: 0.9991\n",
      "Epoch 35/40\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0061 - accuracy: 0.9973\n",
      "Epoch 36/40\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0028 - accuracy: 0.9991\n",
      "Epoch 37/40\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0088 - accuracy: 0.9963\n",
      "Epoch 38/40\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0166 - accuracy: 0.9963\n",
      "Epoch 39/40\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0172 - accuracy: 0.9927\n",
      "Epoch 40/40\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0064 - accuracy: 0.9991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fed94693160>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train_norm, y_train, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b9e6fb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 732.6441 - accuracy: 0.6533\n",
      "test_loss: 732.6441040039062 \n",
      "test_accuracy: 0.653333306312561\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165407f8",
   "metadata": {},
   "source": [
    "-> 제일 높은 점수를 보인 모델 구성에서 에폭 수를 높히니 정확도가 65까지 나왔다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6ceba287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_216 (Conv2D)          (None, 26, 26, 64)        1792      \n",
      "_________________________________________________________________\n",
      "conv2d_217 (Conv2D)          (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_101 (MaxPoolin (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_124 (Dropout)        (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_218 (Conv2D)          (None, 12, 12, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_219 (Conv2D)          (None, 12, 12, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_102 (MaxPoolin (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_125 (Dropout)        (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_220 (Conv2D)          (None, 4, 4, 32)          9248      \n",
      "_________________________________________________________________\n",
      "conv2d_221 (Conv2D)          (None, 2, 2, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_103 (MaxPoolin (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_126 (Dropout)        (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_28 (Flatten)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "dropout_127 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 89,539\n",
      "Trainable params: 89,539\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_channel_1=64\n",
    "n_channel_2=32\n",
    "n_channel_3=32\n",
    "n_dense=128\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Dropout(0.25))\n",
    "\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu',padding='same'))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu', padding='same'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Dropout(0.25))\n",
    "\n",
    "model.add(keras.layers.Conv2D(n_channel_3, (3,3), activation='relu'))\n",
    "model.add(keras.layers.Conv2D(n_channel_3, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Dropout(0.25))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4d545366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "35/35 [==============================] - 1s 6ms/step - loss: 1.1011 - accuracy: 0.3242\n",
      "Epoch 2/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 1.0988 - accuracy: 0.3352\n",
      "Epoch 3/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 1.0941 - accuracy: 0.3699\n",
      "Epoch 4/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.9328 - accuracy: 0.5260\n",
      "Epoch 5/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.7440 - accuracy: 0.5826\n",
      "Epoch 6/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.6871 - accuracy: 0.6119\n",
      "Epoch 7/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.5833 - accuracy: 0.7014\n",
      "Epoch 8/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.5291 - accuracy: 0.7516\n",
      "Epoch 9/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4304 - accuracy: 0.8219\n",
      "Epoch 10/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.3932 - accuracy: 0.8402\n",
      "Epoch 11/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.2452 - accuracy: 0.9151\n",
      "Epoch 12/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2686 - accuracy: 0.9050\n",
      "Epoch 13/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1677 - accuracy: 0.9370\n",
      "Epoch 14/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.1117 - accuracy: 0.9626\n",
      "Epoch 15/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.1259 - accuracy: 0.9461\n",
      "Epoch 16/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0959 - accuracy: 0.9689\n",
      "Epoch 17/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0487 - accuracy: 0.9854\n",
      "Epoch 18/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0477 - accuracy: 0.9845\n",
      "Epoch 19/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0565 - accuracy: 0.9863\n",
      "Epoch 20/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0588 - accuracy: 0.9826\n",
      "Epoch 21/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0386 - accuracy: 0.9890\n",
      "Epoch 22/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0622 - accuracy: 0.9808\n",
      "Epoch 23/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0805 - accuracy: 0.9735\n",
      "Epoch 24/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0509 - accuracy: 0.9836\n",
      "Epoch 25/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0421 - accuracy: 0.9863\n",
      "Epoch 26/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0364 - accuracy: 0.9863\n",
      "Epoch 27/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0237 - accuracy: 0.9936\n",
      "Epoch 28/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0099 - accuracy: 0.9973\n",
      "Epoch 29/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0209 - accuracy: 0.9945\n",
      "Epoch 30/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0375 - accuracy: 0.9854\n",
      "Epoch 31/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0539 - accuracy: 0.9836\n",
      "Epoch 32/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0240 - accuracy: 0.9918\n",
      "Epoch 33/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0127 - accuracy: 0.9973\n",
      "Epoch 34/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0066 - accuracy: 0.9973\n",
      "Epoch 35/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0075 - accuracy: 0.9963\n",
      "Epoch 36/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0157 - accuracy: 0.9954\n",
      "Epoch 37/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0133 - accuracy: 0.9982\n",
      "Epoch 38/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0227 - accuracy: 0.9945\n",
      "Epoch 39/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0132 - accuracy: 0.9973\n",
      "Epoch 40/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0199 - accuracy: 0.9954\n",
      "Epoch 41/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0146 - accuracy: 0.9945\n",
      "Epoch 42/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0092 - accuracy: 0.9963\n",
      "Epoch 43/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0145 - accuracy: 0.9963\n",
      "Epoch 44/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0149 - accuracy: 0.9973\n",
      "Epoch 45/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0101 - accuracy: 0.9963\n",
      "Epoch 46/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0207 - accuracy: 0.9963\n",
      "Epoch 47/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0254 - accuracy: 0.9918\n",
      "Epoch 48/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0101 - accuracy: 0.9982\n",
      "Epoch 49/50\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0033 - accuracy: 0.9973\n",
      "Epoch 50/50\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0035 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fed9427f580>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train_norm, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "09233fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 614.3344 - accuracy: 0.6167\n",
      "test_loss: 614.3344116210938 \n",
      "test_accuracy: 0.6166666746139526\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dc63aa",
   "metadata": {},
   "source": [
    "-> 무조건 에폭 수가 많아진다고 정확도가 높아지지는 않는다, 정확한 지점을 잘 봐야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c03eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화 참고하기\n",
    "hist = model.fit(X_train, Y_train, epochs=1000, batch_size=10, validation_data=(X_val, Y_val))\n",
    "\n",
    "# 5. 모델 학습 과정 표시하기\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4118726d",
   "metadata": {},
   "source": [
    "#### 3. 과적합을 막기 위해 train데이터의 양을 더욱 다양하게 하기\n",
    ":다른 사람의 사진 데이터 300장을 train data에 추가하고 다시 다른 test data로 시도한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ee9d87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a556b3cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9405a37",
   "metadata": {},
   "source": [
    "# 프로젝트 회고\n",
    "\n",
    "## 배운점\n",
    "1. ValueError: Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_61/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_61/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,32], [3,3,32,32]. 오류가 떴다. shape을 맞춰주기 위해 padding = 'same'을 추가하여 해결했다.  \n",
    "\n",
    "## 부족한점\n",
    "\n",
    "## 종합의견\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253a7f44",
   "metadata": {},
   "source": [
    "# Reference\n",
    "1. 케라스 sequential model 참고  \n",
    "https://keras.io/ko/getting-started/sequential-model-guide/    \n",
    "2. 평가지표   \n",
    "https://tykimos.github.io/2017/07/09/Training_Monitoring/  \n",
    "3. 과적합 극복하는 방법  \n",
    "https://wikidocs.net/61374  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e90a9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
